{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezalakha/Quickie/blob/PCA/PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQDrH1re9eB3",
        "colab_type": "text"
      },
      "source": [
        "<h1>This is a basic program implementation containing the use case of PCA</h1>\n",
        "<h3>Hope we all learn something from this tutorial</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rgaIs1JAY2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e84a2883-f1c0-4392-fbd8-49678947031b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSjVKIyK93k8",
        "colab_type": "text"
      },
      "source": [
        "First things First, we look for data. From one of the searches I found a movie rating dataset which is quite common and most of the people  use it for simple demonstration. So decided to use something else on similar grounds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0VFrs44-eVr",
        "colab_type": "text"
      },
      "source": [
        "# Problem Statement: \n",
        " <h3> We will be working on anime ratings dataset where we are gonna reduce the dataset dimensions. The dataset can be found here, </h3>\n",
        "\n",
        "  https://www.kaggle.com/CooperUnion/anime-recommendations-database/download\n",
        "\n",
        "<h4>\n",
        "About the dataset description, it can be found on the website. It's your call to understand the dataset from kaggle platform or do the analysis and learn something in the process</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7OS7Lyx9VHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgrqbjkyFAiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anime = pd.read_csv('/content/drive/My Drive/Projects V.2/lauseeHarbour/Quickie/PCA/anime/anime.csv')\n",
        "rated = pd.read_csv('/content/drive/My Drive/Projects V.2/lauseeHarbour/Quickie/PCA/anime/rating.csv')\n",
        "\n",
        "def replaceName(x):\n",
        "  return anime[anime['anime_id']==x].title.values[0]\n",
        "\n",
        "A = rated.pivot_table(index=[\"user_id\"], columns=[\"anime_id\"], values='rating')\n",
        "a = A.shape\n",
        "df1 = A.replace(np.nan, 0, regex=True)\n",
        "xStd = StandardScaler().fit_transform(df1)\n",
        "\n",
        "meanVector = np.mean(xStd, axis=0)\n",
        "covMatrix = (xStd - meanVector).T.dot((xStd - meanVector)) / (xStd[0] - 1)\n",
        "print('Covariance Matrix \\n%s'%covMatrix)\n",
        "\n",
        "covMatrix = np.cov(xStd.T)\n",
        "eigValues, eigVectors = np.linalg.eig(covMatrix)\n",
        "print(\"EigenVectors \\n%s\"%eigenVectors)\n",
        "print(\"\\nEigenValues \\n%s\"%eigenValues)\n",
        "\n",
        "eigenPairs = [(np.abs(eigValues[i]), eigVectors[:, i]) for i in range(len(eigValues))]\n",
        "\n",
        "pca = PCA(n_components=2).fit_transform(df1)\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNBPaXLUJUK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca2 = PCA().fit_transform(xStd)\n",
        "plt.plot(np.cumsum(pca2.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cli3PQzAXovc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}